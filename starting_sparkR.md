# Máster en Ciencia de Datos e Ingeniería de Computadores. Prácticas de BigData y Cloud Computing. Curso 2016-2017. 

![Header](https://sites.google.com/site/manuparra/home/headerdicits.png)

Manuel J. Parra Royón (manuelparra@decsai.ugr.es) &  José. M. Benítez Sánchez (j.m.benitez@decsai.ugr.es)

[UGR](http://www.ugr.es) | [DICITS](http://dicits.ugr.es) | [SCI2S](http://sci2s.ugr.es) | [DECSAI](http://decsai.ugr.es)

Manuel J. Parra Royón (manuelparra@decsai.ugr.es) & José. M. Benítez Sánchez (j.m.benitez@decsai.ugr.es)

# Primeros pasos SparkR



## Objetivos

Los objetivos del taller de SparkR son los siguientes:

* Conocer la problemática del procesamiento masivo de datos.
* Fijar concepto y práctica sobre uso R sobre Spark para el procesado masivo de datos.
* Instalar y configurar el sistema completo para poder trabajar con R y Spark.
* Trabajar con datos masivos (filtrado, agregado, transformaciones), procesar datasets masivos son SparkSQL, etc..
* Analizar datasets con las librerías de Machine Learning de los paquetes SparkR y sparklry
* Utilizar herramientas para visualizar los datos de datasets masivos.


## Contenido

En el taller de procesamiento masivo de datos con SparkR veremos lo siguiente:

1.- Introducción al procesamiento de datos masivos.
    Breve introducción al procesamiento de datos, el problema de trabajar con grandes conjuntos de datos, Hadoop,Motivación de Spark, características, etc...<BR>

2.- **Notas sobre R, Spark y SparkR**<BR>
    Introducción a R, motivación de R para datos 'pequeños' y datos 'grandes', Spark y sus características, biblioteca de SparkR para análisis de datos masivos con R.<BR>

3.- **Instalación de las herramientas necesarias para el taller**<BR>
    Veremos todas las herramientas necesarias para poder trabajar con el entorno de SparkR, así como la instalación y puesta en marcha de toda la infraestructura necesaria para el taller. Inicio del entorno de trabajo habitual para trabajar en el taller.<BR>

4.- **Entorno de trabajo del taller**<BR>
    Detalles del manejo del entorno de trabajo con JupyterNotebooks y Spark + R<BR>

5.- **Inicio del entorno de trabajo**<BR>
    Flujo de trabajo con Spark + R<BR>

6.- **Primeros pasos con SparkR**<BR>
    Trabajo con ejemplos de uso de Spark + R <BR>

7.- **Lectura y Escritura de datos con SparkR**<BR>
    Trabajo con fuentes de datos, y tipos de conjuntos de datos, CSV, JSON, Parquet, ... Lectura y Escritura. Esquemas, y breve trabajo con SparkSQL. <BR>

8.- **Operaciones y procesado de SparkDataFrames**<BR>
    Trabajamos y procesamos conjuntos de datos masivos con SparkSQL y funciones de agregación, filtrado, selección, etc. Usamos flujos de trabajo con magrittr. Revisamos la funcionalidad completa de la biblioteca de SparkR.<BR>

9.- **Minería de datos con la biblioteca de SparkR**<BR>
    Aplicamos las técnicas de minería de datos y Machine Learning que proporciona SparkR: GLM, KMeans, NaiveBayes y AFT.<BR>

10.- **Minería de datos con la biblioteca sparklyr**<BR>
    Utilizamos la funcionalidad de la biblioteca ``sparklyr`` para procesar conjuntos de datos. Aplicamos los métodos de minería de datos y otras operaciones.<BR>



## Taller práctico de SparkR.

Puedes empezar el taller práctico tanto desde Jupyter como RStudio, siguiendo los siguientes enlaces a la documentación: 

* Parte 1. Teoría: [Presentación del taller](https://github.com/manuparra/taller_sparkR/blob/master/Parte%201.%20S00.%20Presentacion%20del%20Taller.ipynb), 
[Procesamiento masivo de datos](https://github.com/manuparra/taller_sparkR/blob/master/Parte%201.%20S01.%20Procesamiento%20de%20datos%20masivos.ipynb), 
[R+Spark+SparkR](https://github.com/manuparra/taller_sparkR/blob/master/Parte%201.%20S02.%20R%20%2B%20Spark%20%2B%20Datos%20Masivos.ipynb), 
[Instalación de las herramientas](https://github.com/manuparra/taller_sparkR/blob/master/Parte%201.%20S03.%20Instalacion%20de%20las%20herramientas%20para%20el%20Taller%20de%20SparkR.ipynb), 
[Entorno de trabajo](https://github.com/manuparra/taller_sparkR/blob/master/Parte%201.%20S04.%20Entorno%20de%20trabajo%20para%20el%20taller.ipynb)

* [Parte 2. S01. Inicio del entorno de trabajo](https://github.com/manuparra/taller_sparkR/blob/master/Parte%202.%20S01.%20Inicio%20del%20entorno%20de%20trabajo%20con%20SparkR.ipynb)

* [Parte 2. S02. Primer ejemplo con SparkR](https://github.com/manuparra/taller_sparkR/blob/master/Parte%202.%20S02.%20Primer%20ejemplo%20con%20SparkR.ipynb)

* [Parte 2. S03. Lectura y Escritura de datos en SparkR](https://github.com/manuparra/taller_sparkR/blob/master/Parte%202.%20S03.%20Lectura%20y%20escritura%20de%20datos%20con%20SparkR.ipynb)

* [Parte 2. S04. Operaciones con SparkDataFrames](https://github.com/manuparra/taller_sparkR/blob/master/Parte%202.%20S04.%20Operaciones%20con%20SparkDataFrames.ipynb)

* [Parte 2. S05. Minería de datos y Machine Learning con SparkR](https://github.com/manuparra/taller_sparkR/blob/master/Parte%202.%20S05.%20Mineria%20de%20datos%20y%20Machine%20Learning%20con%20SparkR.ipynb)

* [Parte 2. S06. Minería de datos y Machine Learning con sparklyr](https://github.com/manuparra/taller_sparkR/blob/master/Parte%202.%20S06.%20Mineria%20de%20datos%20y%20Machine%20Learning%20con%20sparklyr.ipynb)

* [Parte 2. S07. Visualización de datos masivos con SparkR y Zeppelin](https://github.com/manuparra/taller_sparkR/blob/master/Parte%202.%20S07.%20Visualizacion%20dinamica%20de%20datos%20con%20SparkR.ipynb)
